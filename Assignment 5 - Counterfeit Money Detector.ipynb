{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 5 - Counterfeit Money Detector\n",
    "### By Morgan Kaiser\n",
    "\n",
    "Counterfeit money is a problem businesses need to guard against on an ongoing basis. If a business accepts a fake bill in payment for merchandise or services, they lose both the face value of the bill they received, plus any good or services they provided to the customer who paid with the counterfeit bill.\n",
    "\n",
    "Nowadays, it is too hard to spot counterfeit and genuine bills. You were asked to create a NN model to help organizations to accurately classify counterfeit bills.\n",
    "\n",
    "Data given to you were extracted from images that were taken from genuine and counterfeit bills. A digital image of each bill was taken using an industrial camera, then a wavelet transform tool was used to extract features from these images.\n",
    "\n",
    "Feature Information:\n",
    "\n",
    "1. id: id of the image\n",
    "2. variance: variance of Wavelet Transformed image \n",
    "2. skewness: skewness of Wavelet Transformed image \n",
    "3. curtosis: curtosis of Wavelet Transformed image \n",
    "4. entropy: entropy of image\n",
    "5. class: whether bill is counterfeit or not (1-counterfeit, 0 - genuine)\n",
    "\n",
    "Please answer the following questions: \n",
    "- How many layers are there in your model? How did you decide how many layers to add?\n",
    "- How many neurons are in each of the layers? Why/how did you decide how many neurons to add?\n",
    "- How is the performance of your model? Please interpret your confusion matrix.\n",
    "\n",
    "Note: For any missing values, substitute 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  variance  skewness  kurtosis  entropy  class\n",
       "0   1   3.62160    8.6661   -2.8073 -0.44699      0\n",
       "1   2   4.54590    8.1674   -2.4586 -1.46210      0\n",
       "2   3   3.86600   -2.6383    1.9242  0.10645      0\n",
       "3   4   3.45660    9.5228   -4.0112 -3.59440      0\n",
       "4   5   0.32924   -4.4552    4.5718 -0.98880      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bill_authentication.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1372 entries, 0 to 1371\n",
      "Data columns (total 6 columns):\n",
      "id          1372 non-null int64\n",
      "variance    1372 non-null float64\n",
      "skewness    1342 non-null float64\n",
      "kurtosis    1372 non-null float64\n",
      "entropy     1372 non-null float64\n",
      "class       1372 non-null int64\n",
      "dtypes: float64(4), int64(2)\n",
      "memory usage: 64.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Skewness is missing 30 values. let's take a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>171</td>\n",
       "      <td>0.57060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.242100</td>\n",
       "      <td>-0.562100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>193</td>\n",
       "      <td>1.45780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.178500</td>\n",
       "      <td>0.591360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>227</td>\n",
       "      <td>0.57060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.242100</td>\n",
       "      <td>-0.562100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>233</td>\n",
       "      <td>2.25960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.735500</td>\n",
       "      <td>-0.277600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>273</td>\n",
       "      <td>4.40720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.041600</td>\n",
       "      <td>1.131900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>294</td>\n",
       "      <td>1.93400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.816000</td>\n",
       "      <td>-0.339670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>375</td>\n",
       "      <td>-1.50550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.868100</td>\n",
       "      <td>-0.506480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>381</td>\n",
       "      <td>1.50990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.233200</td>\n",
       "      <td>-0.303460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>0.57060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.242100</td>\n",
       "      <td>-0.562100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>539</td>\n",
       "      <td>0.72252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.670300</td>\n",
       "      <td>-1.350900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>643</td>\n",
       "      <td>5.13210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.326160</td>\n",
       "      <td>1.115100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>669</td>\n",
       "      <td>0.57060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.242100</td>\n",
       "      <td>-0.562080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>692</td>\n",
       "      <td>0.57060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.242100</td>\n",
       "      <td>-0.562100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>730</td>\n",
       "      <td>-0.95923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.220400</td>\n",
       "      <td>-1.482800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>749</td>\n",
       "      <td>0.85574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.604200</td>\n",
       "      <td>-0.531040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>775</td>\n",
       "      <td>-0.61442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.318180</td>\n",
       "      <td>0.502140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>809</td>\n",
       "      <td>-3.02650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.686040</td>\n",
       "      <td>-0.055186</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>810</td>\n",
       "      <td>-1.70150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.993370</td>\n",
       "      <td>-0.531040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>832</td>\n",
       "      <td>-0.39416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.066267</td>\n",
       "      <td>-0.446990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>836</td>\n",
       "      <td>-0.94255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.241920</td>\n",
       "      <td>0.315930</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>945</td>\n",
       "      <td>-2.12100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.949000</td>\n",
       "      <td>1.353000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>1114</td>\n",
       "      <td>-2.68640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.616630</td>\n",
       "      <td>0.061192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>1141</td>\n",
       "      <td>-0.53072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.217930</td>\n",
       "      <td>1.042600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>1159</td>\n",
       "      <td>-3.32030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.961800</td>\n",
       "      <td>-0.449580</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>1176</td>\n",
       "      <td>-1.75490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.757740</td>\n",
       "      <td>-0.370700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>1191</td>\n",
       "      <td>-0.83121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053690</td>\n",
       "      <td>-0.231050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>1202</td>\n",
       "      <td>-0.87340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.201650</td>\n",
       "      <td>0.557740</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>1263</td>\n",
       "      <td>-1.00500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.246200</td>\n",
       "      <td>0.456880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>1320</td>\n",
       "      <td>0.66365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.187940</td>\n",
       "      <td>0.234470</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>1342</td>\n",
       "      <td>-2.26250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.812700</td>\n",
       "      <td>0.486620</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  variance  skewness  kurtosis   entropy  class\n",
       "170    171   0.57060       NaN  1.242100 -0.562100      0\n",
       "192    193   1.45780       NaN  4.178500  0.591360      0\n",
       "226    227   0.57060       NaN  1.242100 -0.562100      0\n",
       "232    233   2.25960       NaN  4.735500 -0.277600      0\n",
       "272    273   4.40720       NaN  2.041600  1.131900      0\n",
       "293    294   1.93400       NaN  4.816000 -0.339670      0\n",
       "374    375  -1.50550       NaN  6.868100 -0.506480      0\n",
       "380    381   1.50990       NaN  6.233200 -0.303460      0\n",
       "498    499   0.57060       NaN  1.242100 -0.562100      0\n",
       "538    539   0.72252       NaN  5.670300 -1.350900      0\n",
       "642    643   5.13210       NaN  0.326160  1.115100      0\n",
       "668    669   0.57060       NaN  1.242100 -0.562080      0\n",
       "691    692   0.57060       NaN  1.242100 -0.562100      0\n",
       "729    730  -0.95923       NaN  6.220400 -1.482800      0\n",
       "748    749   0.85574       NaN  6.604200 -0.531040      0\n",
       "774    775  -0.61442       NaN -0.318180  0.502140      1\n",
       "808    809  -3.02650       NaN  0.686040 -0.055186      1\n",
       "809    810  -1.70150       NaN -0.993370 -0.531040      1\n",
       "831    832  -0.39416       NaN -0.066267 -0.446990      1\n",
       "835    836  -0.94255       NaN -0.241920  0.315930      1\n",
       "944    945  -2.12100       NaN  1.949000  1.353000      1\n",
       "1113  1114  -2.68640       NaN  0.616630  0.061192      1\n",
       "1140  1141  -0.53072       NaN -0.217930  1.042600      1\n",
       "1158  1159  -3.32030       NaN  2.961800 -0.449580      1\n",
       "1175  1176  -1.75490       NaN -0.757740 -0.370700      1\n",
       "1190  1191  -0.83121       NaN  0.053690 -0.231050      1\n",
       "1201  1202  -0.87340       NaN -0.201650  0.557740      1\n",
       "1262  1263  -1.00500       NaN -0.246200  0.456880      1\n",
       "1319  1320   0.66365       NaN -0.187940  0.234470      1\n",
       "1341  1342  -2.26250       NaN  2.812700  0.486620      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding rows with null values\n",
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1372 entries, 0 to 1371\n",
      "Data columns (total 6 columns):\n",
      "id          1372 non-null int64\n",
      "variance    1372 non-null float64\n",
      "skewness    1372 non-null float64\n",
      "kurtosis    1372 non-null float64\n",
      "entropy     1372 non-null float64\n",
      "class       1372 non-null int64\n",
      "dtypes: float64(4), int64(2)\n",
      "memory usage: 64.4 KB\n"
     ]
    }
   ],
   "source": [
    "# alright, doesn't matter for this though. replace all NaN vals with zero.\n",
    "\n",
    "df['skewness'].fillna(0, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "      <td>1372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>1.922896</td>\n",
       "      <td>1.397627</td>\n",
       "      <td>-1.191657</td>\n",
       "      <td>0.444606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>396.206596</td>\n",
       "      <td>2.842763</td>\n",
       "      <td>5.868862</td>\n",
       "      <td>4.310030</td>\n",
       "      <td>2.101013</td>\n",
       "      <td>0.497103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-7.042100</td>\n",
       "      <td>-13.773100</td>\n",
       "      <td>-5.286100</td>\n",
       "      <td>-8.548200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>343.750000</td>\n",
       "      <td>-1.773000</td>\n",
       "      <td>-1.708200</td>\n",
       "      <td>-1.574975</td>\n",
       "      <td>-2.413450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.496180</td>\n",
       "      <td>2.319650</td>\n",
       "      <td>0.616630</td>\n",
       "      <td>-0.586650</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1029.250000</td>\n",
       "      <td>2.821475</td>\n",
       "      <td>6.814625</td>\n",
       "      <td>3.179250</td>\n",
       "      <td>0.394810</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1372.000000</td>\n",
       "      <td>6.824800</td>\n",
       "      <td>12.951600</td>\n",
       "      <td>17.927400</td>\n",
       "      <td>2.449500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id     variance     skewness     kurtosis      entropy  \\\n",
       "count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000   \n",
       "mean    686.500000     0.433735     1.922896     1.397627    -1.191657   \n",
       "std     396.206596     2.842763     5.868862     4.310030     2.101013   \n",
       "min       1.000000    -7.042100   -13.773100    -5.286100    -8.548200   \n",
       "25%     343.750000    -1.773000    -1.708200    -1.574975    -2.413450   \n",
       "50%     686.500000     0.496180     2.319650     0.616630    -0.586650   \n",
       "75%    1029.250000     2.821475     6.814625     3.179250     0.394810   \n",
       "max    1372.000000     6.824800    12.951600    17.927400     2.449500   \n",
       "\n",
       "             class  \n",
       "count  1372.000000  \n",
       "mean      0.444606  \n",
       "std       0.497103  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> values don't swing too widely\n",
    "\n",
    "> close in scale, but will still scale due to using NN model\n",
    "\n",
    "> class is a binary attribute (1=counterfeit, 0=genuine) but mean = 0.44. As this number is below 0.5, this means there are more genuine bills in this dataset than counterfeit bills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2102ef819b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's verify our interpretation of the class variable\n",
    "sns.countplot(x=\"class\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 0 categorical variables -> no need to get dummies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Keras to build NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the NN object, since we are doing classification, I called it classifier -> from Dr. Ozturk's NN with Python file\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer and first hidden layer\n",
    "classifier.add(Dense(input_dim=4, units=3, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where...\n",
    "\n",
    "- input_dim: number of neurons in input layer\n",
    "  - should be equal to how many independent variables (IVs aka inputs) there are\n",
    "  \n",
    "- units: number of neurons in hidden layer\n",
    "  - rule of thumb is to add input layer and output layer together and take average\n",
    "  \n",
    "- activation: relu is most common and widely accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer\n",
    "classifier.add(Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Output layer should be equal to what we are predicting. Since we are doing classification, we want 1 answer (the bill is counterfeit OR the bill is genuine). So number of neurons is only 1 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Morgan Kaiser\\Anaconda3\\Anaconda\\New folder\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/20\n",
      "1097/1097 [==============================] - 0s 392us/step - loss: 0.8477 - acc: 0.3573\n",
      "Epoch 2/20\n",
      "1097/1097 [==============================] - 0s 127us/step - loss: 0.7240 - acc: 0.5178\n",
      "Epoch 3/20\n",
      "1097/1097 [==============================] - 0s 123us/step - loss: 0.6165 - acc: 0.7074\n",
      "Epoch 4/20\n",
      "1097/1097 [==============================] - 0s 138us/step - loss: 0.5236 - acc: 0.8067\n",
      "Epoch 5/20\n",
      "1097/1097 [==============================] - 0s 135us/step - loss: 0.4467 - acc: 0.8587\n",
      "Epoch 6/20\n",
      "1097/1097 [==============================] - 0s 130us/step - loss: 0.3852 - acc: 0.8751\n",
      "Epoch 7/20\n",
      "1097/1097 [==============================] - 0s 132us/step - loss: 0.3354 - acc: 0.9006\n",
      "Epoch 8/20\n",
      "1097/1097 [==============================] - 0s 127us/step - loss: 0.2951 - acc: 0.9143\n",
      "Epoch 9/20\n",
      "1097/1097 [==============================] - 0s 134us/step - loss: 0.2614 - acc: 0.9262\n",
      "Epoch 10/20\n",
      "1097/1097 [==============================] - 0s 124us/step - loss: 0.2332 - acc: 0.9353\n",
      "Epoch 11/20\n",
      "1097/1097 [==============================] - 0s 124us/step - loss: 0.2094 - acc: 0.9426\n",
      "Epoch 12/20\n",
      "1097/1097 [==============================] - 0s 128us/step - loss: 0.1886 - acc: 0.9480\n",
      "Epoch 13/20\n",
      "1097/1097 [==============================] - 0s 125us/step - loss: 0.1710 - acc: 0.9553\n",
      "Epoch 14/20\n",
      "1097/1097 [==============================] - 0s 124us/step - loss: 0.1560 - acc: 0.9581\n",
      "Epoch 15/20\n",
      "1097/1097 [==============================] - 0s 126us/step - loss: 0.1428 - acc: 0.9608\n",
      "Epoch 16/20\n",
      "1097/1097 [==============================] - 0s 159us/step - loss: 0.1308 - acc: 0.9654\n",
      "Epoch 17/20\n",
      "1097/1097 [==============================] - 0s 114us/step - loss: 0.1199 - acc: 0.9681\n",
      "Epoch 18/20\n",
      "1097/1097 [==============================] - 0s 115us/step - loss: 0.1094 - acc: 0.9708\n",
      "Epoch 19/20\n",
      "1097/1097 [==============================] - 0s 112us/step - loss: 0.0988 - acc: 0.9717\n",
      "Epoch 20/20\n",
      "1097/1097 [==============================] - 0s 115us/step - loss: 0.0891 - acc: 0.9754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x210351bbe10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train, epochs=20, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[152,   5],\n",
       "       [  0, 118]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       157\n",
      "           1       0.96      1.00      0.98       118\n",
      "\n",
      "    accuracy                           0.98       275\n",
      "   macro avg       0.98      0.98      0.98       275\n",
      "weighted avg       0.98      0.98      0.98       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "**1. How many layers are there in your model? How did you decide how many layers to add?**\n",
    "  - 3 layers: 1 input, 1 hidden, 1 output.\n",
    "\n",
    "  - There is no support showing it is necessary to build more than 2 hidden layers.\n",
    "    - As our data isn't overly complex and dataset is rather tiny, I opted for 1 hidden layer.\n",
    "\n",
    "**2. How many neurons are in each of the layers? Why/how did you decide how many neurons to add?**\n",
    "  - input\n",
    "    - 4 neurons because there are 4 IVs.\n",
    "\n",
    "  - hidden\n",
    "    - 3 neurons because I added the input layer and output layer together then took around 2/3 of the value.\n",
    "    - 4+1=5 then 5*(2/3) is a little above 3.\n",
    "\n",
    "  - output\n",
    "    - 1 neuron because it is a classification problem and I want 1 answer.\n",
    "    - Either the bill is genuine, or the bill is counterfeit.\n",
    "\n",
    "**3. How is the performance of your model? Please interpret your confusion matrix.**\n",
    "  - Model has 98% accuracy\n",
    "  - True Positives: 152 genuine bills\n",
    "  - False Negatives: 5 genuine bills were incorrectly classified as counterfeit\n",
    "  - True Negatives: 118 counterfeit bills\n",
    "  - False Positives: 0 counterfeit bills were incorrectly classified as genuine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
